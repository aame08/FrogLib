{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d37edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотек\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea322c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Короткая задержка между последовательными запросами\n",
    "def get_short_delay():\n",
    "    return random.uniform(2, 5)\n",
    "\n",
    "# Средняя задержка после важных действий\n",
    "def get_medium_delay():\n",
    "    return random.uniform(7, 15)\n",
    "\n",
    "# Длинная задержка при подозрении на блокировку\n",
    "def get_long_delay():\n",
    "    return random.uniform(30, 90)\n",
    "\n",
    "# Очень длинная задержка при обнаружении блокировки\n",
    "def get_extended_delay():\n",
    "    return random.uniform(120, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f341503",
   "metadata": {},
   "source": [
    "### Парсинг рецензий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19197d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Структуры для хранения данных\n",
    "reviews_list = {\n",
    "    'id': [],\n",
    "    'author_name': [],\n",
    "    'book_slug': [],\n",
    "    'title_book': [],\n",
    "    'review_url': [],\n",
    "    'author_book': [],\n",
    "    'date_creation': [],\n",
    "    'count_view': [],\n",
    "    'evaluation': [],\n",
    "    'title_review': [],\n",
    "    'text_review': [],\n",
    "    'count_like': [],\n",
    "    'count_comment': []\n",
    "}\n",
    "\n",
    "comments_reviews_list = {\n",
    "    'id_review': [],\n",
    "    'id_comment': [],\n",
    "    'author_comment': [],\n",
    "    'date_comment': [],\n",
    "    'text_comment': [],\n",
    "    'parent_comment': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac72ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки\n",
    "headers = {'User-Agent': UserAgent().random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87418f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг комментариев к рецензии\n",
    "def parse_review_comments(review_id, review_url):\n",
    "    try:\n",
    "        comments_url = f\"{review_url}#comments\"\n",
    "        print(f'[{datetime.now().strftime('%H:%M:%S')}] Загрузка комментариев для рецензии {review_id}.')\n",
    "        \n",
    "        # Первая задержка перед загрузкой комментариев\n",
    "        time.sleep(get_medium_delay())\n",
    "\n",
    "        page = requests.get(comments_url, headers=headers, timeout=20)\n",
    "        \n",
    "        if page.status_code != 200:\n",
    "            print(f'Ошибка загрузки: {page.status_code}.')\n",
    "            return\n",
    "        \n",
    "        soup = bs(page.text, 'html.parser')\n",
    "        comments = soup.find_all('div', class_=lambda x: x and 'comment-row' in x)\n",
    "        \n",
    "        if not comments:\n",
    "            print('Комментарии не найдены.')\n",
    "            return\n",
    "        \n",
    "        print(f'Найдено {len(comments)} комментариев.')\n",
    "        \n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            try:\n",
    "                # Задержка между комментариями\n",
    "                if i % 3 == 0:\n",
    "                    time.sleep(get_medium_delay())\n",
    "                else:\n",
    "                    time.sleep(get_short_delay())\n",
    "                \n",
    "                # ID комментария\n",
    "                comment_id = comment.get('id', '').replace('comment', '') or None\n",
    "                \n",
    "                # Уровень вложенности\n",
    "                comment_level = 1\n",
    "                level_class = [c for c in comment.get('class', []) if 'comment-level' in c]\n",
    "                if level_class:\n",
    "                    level_match = re.search(r'comment-level(\\d+)', level_class[0])\n",
    "                    comment_level = int(level_match.group(1)) if level_match else 1\n",
    "                \n",
    "                # Автор\n",
    "                author_tag = comment.find('a', class_='comment-user-avatar')\n",
    "                author = author_tag.get('title', 'Аноним') if author_tag else \"Аноним\"\n",
    "                \n",
    "                # Дата\n",
    "                date_span = comment.find('span', class_='event-user-date')\n",
    "                date = date_span.get_text(strip=True) if date_span else None\n",
    "                \n",
    "                # Текст комментария\n",
    "                text_div = comment.find('div', class_='commenttext')\n",
    "                text = None\n",
    "                if text_div:\n",
    "                    for img in text_div.find_all('img'):\n",
    "                        img.decompose()\n",
    "                    text = ' '.join(text_div.stripped_strings)\n",
    "                \n",
    "                # Родительский комментарий\n",
    "                parent_comment = None\n",
    "                if comment_level > 1:\n",
    "                    up_link = comment.find('a', string='Уровень вверх')\n",
    "                    if up_link:\n",
    "                        parent_match = re.search(r'comment(\\d+)', up_link.get('href', ''))\n",
    "                        parent_comment = parent_match.group(1) if parent_match else None\n",
    "                \n",
    "                # Сохранение данных\n",
    "                comments_reviews_list['id_review'].append(review_id)\n",
    "                comments_reviews_list['id_comment'].append(comment_id)\n",
    "                comments_reviews_list['author_comment'].append(author)\n",
    "                comments_reviews_list['date_comment'].append(date)\n",
    "                comments_reviews_list['text_comment'].append(text)\n",
    "                comments_reviews_list['parent_comment'].append(parent_comment)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f'Ошибка обработки комментария: {str(e)} .')\n",
    "                time.sleep(get_medium_delay())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Ошибка загрузки комментариев: {str(e)} .')\n",
    "        time.sleep(get_long_delay())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196067e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг текста рецензии\n",
    "def parse_review_text(text_block):\n",
    "    if not text_block:\n",
    "        return ''\n",
    "    \n",
    "    review_body = text_block.find('div', itemprop='reviewBody')\n",
    "    if not review_body:\n",
    "        return ''\n",
    "    \n",
    "    # Удаление всех изображений и их обертки\n",
    "    for img in review_body.find_all('img'):\n",
    "        img.decompose()\n",
    "    for a in review_body.find_all('a'):\n",
    "        if a.find('img'):\n",
    "            a.decompose()\n",
    "    \n",
    "    # Обработка каждого элемента содержимого\n",
    "    processed_text = []\n",
    "    \n",
    "    for element in review_body.children:\n",
    "        if element.name == 'p':\n",
    "            # Обработка содержимого параграфа\n",
    "            para_content = []\n",
    "            for content in element.contents:\n",
    "                if content.name in ['b', 'i', 'u', 'a', 'span']:\n",
    "                    # Сохранение тегов форматирования\n",
    "                    tag = content.name\n",
    "                    text = content.get_text()\n",
    "                    if tag == 'a' or tag == 'span':\n",
    "                        para_content.append(text)\n",
    "                    else:\n",
    "                        para_content.append(f'<{tag}>{text}</{tag}>')\n",
    "                elif content.name is None:\n",
    "                    para_content.append(str(content))\n",
    "            \n",
    "            # Сбор текста параграфа и добавление <br>\n",
    "            para_text = ''.join(para_content).strip()\n",
    "            if para_text:\n",
    "                processed_text.append(para_text)\n",
    "                processed_text.append('<br><br>')  # Двойной <br> для абзаца\n",
    "        \n",
    "        elif element.name == 'br':\n",
    "            processed_text.append('<br>')\n",
    "    \n",
    "    # Объединение все части\n",
    "    final_text = ''.join(processed_text)\n",
    "    \n",
    "    # Очистка лишние переносы\n",
    "    final_text = re.sub(r'(<br>\\s*){3,}', '<br><br>', final_text)\n",
    "    final_text = final_text.strip()\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция парсинга рецензий\n",
    "def scrape_reviews(start_page=1, max_pages=5):\n",
    "    pagenum = start_page\n",
    "    request_count = 0\n",
    "\n",
    "    for _ in range(max_pages):\n",
    "        try:\n",
    "            url = f'https://www.livelib.ru/reviews/~{pagenum}'\n",
    "            print(f'\\n[{datetime.now().strftime('%H:%M:%S')}] Страница {pagenum}: {url} .')\n",
    "\n",
    "            # Управление задержками\n",
    "            request_count += 1\n",
    "            if request_count % 3 == 0:\n",
    "                delay = get_long_delay()\n",
    "                print(f'Большая пауза на {delay:.1f} сек...')\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                time.sleep(get_medium_delay())\n",
    "\n",
    "            # Загрузка страницы\n",
    "            page = requests.get(url, headers=headers, timeout=30)\n",
    "            print(page.text)\n",
    "\n",
    "            # Проверка на блокировку\n",
    "            if 'идёт слишком много запросов' in page.text:\n",
    "                delay = get_extended_delay()\n",
    "                print(f'Блокировка. Большая пауза ({delay:.1f} сек).')\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "\n",
    "            if page.status_code != 200:\n",
    "                print(f'Ошибка загрузки страницы: {page.status_code}.')\n",
    "                time.sleep(get_extended_delay())\n",
    "                continue\n",
    "\n",
    "            soup = bs(page.text, 'html.parser')\n",
    "            print(soup)\n",
    "\n",
    "            # Проверка на пустую страницу\n",
    "            review_cards = soup.find_all('article', class_=lambda x: x and 'review-card' in x)\n",
    "            if not review_cards:\n",
    "                print('Рецензии не найдены, возможно блокировка или последняя страница.')\n",
    "                time.sleep(get_extended_delay())\n",
    "                break\n",
    "\n",
    "            print(f'Найдено {len(review_cards)} рецензий.')\n",
    "\n",
    "            # Обработка каждой рецензии\n",
    "            for i, review_card in enumerate(review_cards, 1):\n",
    "                try:\n",
    "                    if i % 5 == 0:\n",
    "                        time.sleep(get_medium_delay())\n",
    "                    else:\n",
    "                        time.sleep(get_short_delay())\n",
    "\n",
    "                    # Базовые данные\n",
    "                    title_block = review_card.find('h3', class_='lenta-card__title')\n",
    "                    if not title_block:\n",
    "                        continue\n",
    "\n",
    "                    review_link = title_block.find('a', href=True)\n",
    "                    if not review_link:\n",
    "                        continue\n",
    "\n",
    "                    href = review_link['href']\n",
    "                    match = re.search(r'/review/(\\d+)', href)\n",
    "                    if not match:\n",
    "                        continue\n",
    "\n",
    "                    review_id = match.group(1)\n",
    "                    review_url = urljoin('https://www.livelib.ru', href)\n",
    "\n",
    "                    # Автор рецензии\n",
    "                    author_item = review_card.find('a', class_='header-card-user__name')\n",
    "                    author_name = author_item.get_text(strip=True) if author_item else 'Неизвестно'\n",
    "\n",
    "                    # Информация о книге\n",
    "                    book_title_link = review_card.find('a', class_='lenta-card__book-title')\n",
    "                    title = book_title_link.get_text(strip=True).strip('\"') if book_title_link else None\n",
    "\n",
    "                    book_slug = None\n",
    "                    if book_title_link:\n",
    "                        href = book_title_link.get('href', '')\n",
    "                        book_slug_match = re.search(r'/(?:work|book)/(\\d+[-_\\w]*)', href)\n",
    "                        book_slug = book_slug_match.group(1) if book_slug_match else None\n",
    "\n",
    "                    # Авторы книги\n",
    "                    author_container = review_card.find('p', class_='lenta-card__author-wrap')\n",
    "                    author_book = 'Автор неизвестен'\n",
    "                    if author_container:\n",
    "                        author_links = author_container.find_all('a', class_='lenta-card__author')\n",
    "                        authors = [link.get_text(strip=True) for link in author_links if link.get_text(strip=True)]\n",
    "                        author_book = ', '.join(authors) if authors else author_book\n",
    "\n",
    "                    # Загрузка страницы рецензии с задержкой\n",
    "                    time.sleep(get_short_delay())\n",
    "                    review_page = requests.get(review_url, headers=headers, timeout=30)\n",
    "\n",
    "                    if review_page.status_code != 200:\n",
    "                        print(f'Ошибка загрузки рецензии {review_id}: {review_page.status_code}.')\n",
    "                        time.sleep(get_long_delay())\n",
    "                        continue\n",
    "\n",
    "                    review_soup = bs(review_page.text, 'html.parser')\n",
    "\n",
    "                    # Дата и просмотры\n",
    "                    review_details = review_soup.find('div', class_='lenta-card__details')\n",
    "                    date_creation = 'Дата не указана'\n",
    "                    count_view = '0'\n",
    "\n",
    "                    if review_details:\n",
    "                        date_time = review_details.find('p', class_='lenta-card__date')\n",
    "                        date_creation = date_time.get_text(strip=True).replace('&nbsp;', ' ') if date_time else date_creation\n",
    "\n",
    "                        count_view_item = review_details.find('p', class_='lenta-card__aliases')\n",
    "                        count_view = count_view_item.find('span').get_text(strip=True) if count_view_item else count_view\n",
    "                        \n",
    "                    # Оценка и заголовок\n",
    "                    review_title_block = review_soup.find('h1', class_='lenta-card__title')\n",
    "                    evaluation = '0'\n",
    "                    title_review = 'Нет названия'\n",
    "\n",
    "                    if review_title_block:\n",
    "                        rating_span = review_title_block.find('span', class_='lenta-card__mymark')\n",
    "                        evaluation = rating_span.get_text(strip=True) if rating_span else evaluation\n",
    "\n",
    "                        if rating_span:\n",
    "                            rating_span.decompose()\n",
    "                        title_review = review_title_block.get_text(strip=True)\n",
    "\n",
    "                    if not evaluation:\n",
    "                        continue\n",
    "\n",
    "                    # Текст рецензии\n",
    "                    text_block = review_soup.find('div', class_='lenta-card__text')\n",
    "                    final_text = parse_review_text(text_block) if text_block else ''\n",
    "\n",
    "                    # Лайки и комментарии\n",
    "                    footer_container = review_soup.find('div', class_='footer-card__soc-active')\n",
    "                    like_count = '0'\n",
    "                    comment_count = '0'\n",
    "\n",
    "                    if footer_container:\n",
    "                        like_element = footer_container.find('a', class_='icon-like')\n",
    "                        if like_element:\n",
    "                            like_count_span = like_element.find('span', class_='sub__link-count')\n",
    "                            like_count = like_count_span.get_text(strip=True) if like_count_span else like_count\n",
    "\n",
    "                        comment_element = footer_container.find('a', class_='icon-comment')\n",
    "                        if comment_element:\n",
    "                            comment_count_span = comment_element.find('span')\n",
    "                            comment_count = comment_count_span.get_text(strip=True) if comment_count_span else comment_count\n",
    "\n",
    "                    # Парсинг комментариев (если есть)\n",
    "                    if comment_count != '0':\n",
    "                        parse_review_comments(review_id, review_url)\n",
    "\n",
    "                    # Сохранение данных\n",
    "                    reviews_list['id'].append(review_id)\n",
    "                    reviews_list['author_name'].append(author_name)\n",
    "                    reviews_list['book_slug'].append(book_slug)\n",
    "                    reviews_list['title_book'].append(title)\n",
    "                    reviews_list['review_url'].append(review_url)\n",
    "                    reviews_list['author_book'].append(author_book)\n",
    "                    reviews_list['date_creation'].append(date_creation)\n",
    "                    reviews_list['count_view'].append(count_view)\n",
    "                    reviews_list['evaluation'].append(evaluation)\n",
    "                    reviews_list['title_review'].append(title_review)\n",
    "                    reviews_list['text_review'].append(final_text)\n",
    "                    reviews_list['count_like'].append(like_count)\n",
    "                    reviews_list['count_comment'].append(comment_count)\n",
    "\n",
    "                    print(f'Обработана рецензия: {review_id}.')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка обработки рецензии: {str(e)} .')\n",
    "\n",
    "            pagenum += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Критическая ошибка: {str(e)} .')\n",
    "            time.sleep(get_extended_delay())\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ad934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало парсинга: 16:50:03\n",
      "\n",
      "[16:50:03] Страница 1: https://www.livelib.ru/reviews/~1 .\n",
      "Блокировка. Очень большая пауза...\n",
      "\n",
      "[16:56:05] Страница 1: https://www.livelib.ru/reviews/~1 .\n",
      "Блокировка. Очень большая пауза...\n",
      "\n",
      "[17:01:47] Страница 1: https://www.livelib.ru/reviews/~1 .\n",
      "Большая пауза на 43.5 сек...\n",
      "Блокировка. Очень большая пауза...\n",
      "\n",
      "[17:08:57] Страница 1: https://www.livelib.ru/reviews/~1 .\n",
      "Блокировка. Очень большая пауза...\n"
     ]
    }
   ],
   "source": [
    "print(f'Начало парсинга: {datetime.now().strftime('%H:%M:%S')}')\n",
    "scrape_reviews(start_page=1, max_pages=5)\n",
    "print(f'Завершение парсинга: {datetime.now().strftime('%H:%M:%S')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399606dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество нулевых значений в reviews_list:\n",
      "id - 0\n",
      "author_name - 0\n",
      "book_slug - 0\n",
      "title_book - 0\n",
      "review_url - 0\n",
      "author_book - 0\n",
      "date_creation - 0\n",
      "count_view - 0\n",
      "evaluation - 0\n",
      "title_review - 0\n",
      "text_review - 0\n",
      "count_like - 0\n",
      "count_comment - 0\n",
      "\n",
      "Количество нулевых значений в comments_reviews_list:\n",
      "id_review - 0\n",
      "id_comment - 0\n",
      "author_comment - 0\n",
      "date_comment - 0\n",
      "text_comment - 0\n",
      "parent_comment - 3\n"
     ]
    }
   ],
   "source": [
    "# Просмотр количества пропусков\n",
    "print('Количество нулевых значений в reviews_list:')\n",
    "for i in reviews_list:\n",
    "    print( i + \" - \" + str(reviews_list[i].count(None)))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Количество нулевых значений в comments_reviews_list:')\n",
    "for i in comments_reviews_list:\n",
    "    print( i + \" - \" + str(comments_reviews_list[i].count(None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f07dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "book_slug",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title_book",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_book",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_creation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count_view",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "evaluation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count_like",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count_comment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "165407a9-aac9-4514-a000-b5f57013575d",
       "rows": [
        [
         "0",
         "5071651",
         "Чубаркина Наталья Михайловна",
         "1008751306-na-izyaschnom-mify-v-iskusstve-sovremennyj-vzglyad-na-drevnegrecheskie-mify-mariya-aboronova",
         "#На изящном: мифы в искусстве. Современный взгляд на древнегреческие мифы",
         "https://www.livelib.ru/review/5071651-na-izyaschnom-mify-v-iskusstve-sovremennyj-vzglyad-na-drevnegrecheskie-mify-mariya-aboronova",
         "Мария Аборонова",
         "11 мая 2025 г. 10:23",
         "0",
         "1",
         "О мифах языком камеди- клаба.",
         "1 из 5⭐О необходимости книги мы судим сначала по её названию, верно? Вот и я подумала, что лучше разберусь в мире античных мифов, в том, как они повлияли на искусство всех времён, если прочитаю эту книгу. Но <b>разочарование меня постигло прям в самом начале.</b> Может, и хорошо, что так. Зато не было потрачено много времени на некачественную книгу.Уже на 6 из 467 страниц электронной книги я встречаю такое:<br><br>Эней- создатель троянского коня? Точно??? <b>Как можно взяться за тему, в которой путаешься</b> и называешь Энея создателем орудия, которое помогло разрушить твой же город? Автор точно знает, на чьей стороне был Эней? То есть правнук основателя Трои сам создал троянского коня? И Вергилий написал о предателе поэму, чтобы потом император Август мог сказать, что его род от Энея- предателя? Я верно понимаю? <b>Или автор троллит читателей? Или сама плавает в мифологии, путая Эпея и Энея?</b>Ну и, <b>как оказалось, вся книга будет написана в подобном стиле пересказа античных мифов</b>:<br><br>Как признаётся сама Мария Аборонова, книга родилась из постов в её телеграм- канале<b>. </b><b>Видимо, автор решила, что её читатели иначе ничего не поймут, поэтому старательно юморила</b>:<br><br><b>Нет, </b><b>в принципе, автор излагала понятно</b>. Но при этом ощущаешь себя человеком ущербным, с которым надо говорить на языке камеди-клаба. <b>На втором десятке страниц книги ты понимаешь, что просто противно читать дальше. </b><b>Итог</b>: книга бегло пролистана, просмотрены <b>иллюстрации (это единственный плюс электронной книги),</b> эпизодически по диагонали прочитаны еще несколько страниц.Например, о Троянской войне автор пишет:<br><br>То есть всё настолько <b>поверхностно</b>? Автор современному читателю, особенно молодому и неопытному, просто разъясняет  буквальный слой и считает это достаточным? По тому, как автор объясняет причины Троянской войны, я пониманию уровень знаний самого автора.<br><br>",
         "1",
         "0"
        ],
        [
         "1",
         "5071642",
         "nat_phil",
         "1000460354-atlant-raspravil-plechi-v-3-chastyah-chast-2-iliili-ajn-rend",
         "Атлант расправил плечи. В 3 частях. Часть 2. Или-или",
         "https://www.livelib.ru/review/5071642-atlant-raspravil-plechi-v-3-chastyah-chast-2-iliili-ajn-rend",
         "Айн Рэнд",
         "11 мая 2025 г. 10:19",
         "0",
         "5",
         "Гнев да и только",
         "Эта книжка меня жутко бесила: в смысле автор пишет об эгоистах, которые на пресс-конференциях в открытую говорят, что просто хотят нажиться на народе??? Почему я должна вникать в то, как у этих эгоистов все утроено в голове и жизни???<br><br>Я даже хотела ее бросить, несколько раз, но тогда у меня еще был парень, перед которым у меня были моральные обязательства (мы типа книжки вместе читали). Книжку не бросила, бросила парня.<br><br>Из очень прикольного в \"Атланте\": перед тем как заняться сексом впервые, изменив, конечно, семье, один из главных героев и Дагни такие: \"...и то, что сейчас произойдет, тоже часть нашего дела, нашей борьбы!..\"<br><br>Чудно. Типа панки. Наделим просто антинорму и просто химию идейным содержанием.<br><br>Когда мы подходили к утопии Дж. Голда (я аудио слушала, я не знаю, как он пишется), а героиня уже переспала с двумя из кучки избранных, я думала: как же они, типа эгоисты, будут сосуществовать на одном пяточке, имея общую женщину?? И ей, самое главное, норм. Ну и что, что много, зато все вон какие хорошие! Не серая масса, баблом воротят, умные. Про совместительство такое - привет, Чернышевский. (Кстати, мне соседка сказала, что имя Айн Рэнд связывают с теорией разумного эгоизма, которая (теория) как раз про \"Что делать?\", как мне казалось, но тут вообще не тот разумный эгоизм!)<br><br>О чем я? Ах, да. Было так удивительно узнать, что потом Дагни еще и с вождем утопии, конечно.<br><br>(да, я тут пишу, как серая масса, которые друзья из утопии только и делают, что презирают)<br><br>(и да, я должна подумать на досуге с дневником, почему меня так бесит все, что меня тут бесит)<br><br>Из хорошего.<br><br>Меня очень умиляет традция Дагни и Франциско д'Анконии:<br><br>— Привет, Чушка!<br><br>— Привет, Фриско!Я бы тоже хотела так: редко видимся, почти детские цитаты.Выплеснула яд, пойду к дневнику, отрефлексирую комплексы.P.S. Увидела, что поставила книжке пять... Видимо, за гнев. Не оставить равнодушным - тоже талант?<br><br>",
         "0",
         "0"
        ],
        [
         "2",
         "5071639",
         "Крупкина Мария",
         "1008875347-na-zapadnom-fronte-bez-peremen-erih-mariya-remark",
         "На Западном фронте без перемен",
         "https://www.livelib.ru/review/5071639-na-zapadnom-fronte-bez-peremen-erih-mariya-remark",
         "Эрих Мария Ремарк",
         "11 мая 2025 г. 10:18",
         "0",
         "5",
         "СпойлерУжасы войны",
         "Сразу после школы в 19 лет Пауля Боймера и его одноклассников мы видим на поле боя: Леера, Мюллера, Альберта Кроппа, Кеммериха.  А также Тьядена, Хайе Вестхуса, Стаса Катчинского (Ката, 40 лет), Детеринга. \"Чей-то приказ превратил эти безмолвные фигуры в наших врагов, другой приказ мог бы превратить их в наших друзей\".<br><br>",
         "1",
         "0"
        ],
        [
         "3",
         "5071636",
         "Жукова Елена",
         "1010717885-sirena-morskih-glubin-sumi-han",
         "Сирена морских глубин",
         "https://www.livelib.ru/review/5071636-sirena-morskih-glubin-sumi-han",
         "Суми Хан",
         "11 мая 2025 г. 10:17",
         "0",
         "3",
         "Эх, разочарование...",
         "«Жить — значит выживать и выполнять свой долг, зарабатывать на пропитание и заботиться о своей семье. Она всегда делала то, что надо делать.»<br><br>Действие происходит в середине прошлого века на корейском острове Чеджудо. Японская оккупация закончилась, началась американская. Идёт активная охота на коммунистов, а фактически просто беспредел.\n          Юная Чунчжа — потомственная ныряльщица, добывает со дна океана водоросли и устрицы. Однажды она, вместо мамы, отправляется в горы к знакомой семье обменять морепродукты на поросёнка. В пути она встречает свою первую любовь, но вернувшись, находит мать избитой до смерти.<br><br>Первая часть романа читалась с интересом — я окунулась в атмосферу острова, переживала за героев, пыталась понять, что происходит. Но мне не хватило глубины в характерах персонажей и подробностей политической обстановки.\n          Во второй части мы переносимся в 2001 год в Америку, где пожилая Чунчжа умирает, а потом преследует своего мужа в виде призрака‍. Дальше больше — шаманы, общение с дУхами умерших... Интерес резко упал, я откровенно пролистывала эту дичь.<br><br>Самым интересным персонажем для меня был констебль, на втором месте — бабушка Чунчжи. Сама же главная героиня постепенно стушëвывалась, уходила на второй план. Последние главы вообще не про неё‍.           \n          Я понимаю, что это проба пера, но автор попыталась охватить самые популярные темы — тут и война, и любовь, и привидения, и две временные линии... И всё это на очень небольшом объёме (не смотрите на количество страниц — крупный шрифт + поля + каждая глава с новой страницы). В общем, получилось как-то рвано и скомкано, я не прониклась, дочитывала откровенно нехотя.<br><br>",
         "1",
         "0"
        ],
        [
         "4",
         "5071624",
         "Booksevil",
         "1005765304-lyubimets-kir-bulychjov",
         "Любимец",
         "https://www.livelib.ru/review/5071624-lyubimets-kir-bulychjov",
         "Кир Булычёв",
         "11 мая 2025 г. 10:11",
         "0",
         "3",
         "СпойлерСказ о том, как межпланетные лягухи нарушили первую директиву...",
         "Планета Земля. Она молода, красива и зелена. Она дом для множества форм жизни. Да, они не всегда в ладах друг с другом, но они полны надежд и веры в светлое будущее (в основном сапиенсы). Но в один прекрасный день жизнь нашей малышки Земли кардинально меняется, когда на неё высаживаются космические разумные лягухи. И вот оно будущее, уже тут, покоряйте просторы, делитесь открытиями, дерзайте...Однако в каждой истории всегда найдётся своё Но(!).<br><br>Задел интересный скажете вы, и я соглашусь, но вот исполнение подкачало. Да, слог достаточно лёгкий, а вот сам текст, я ему не верила. У меня остались вопросы, на которые ответов я не получила. Непонятны моменты, которые, по моему мнению, кардинально противоречат главным постулатам описанного мира. И да, я говорю про умение читать в мире, где читать людям запрещено. Так нам и не объяснили вундеркинд Тим, или просто его учили в питомнике. В последней главе его лексикон вообще изобилует, ну неправдиво как по мне. Может автор так пытался показать рост персонажа? Если да, то это только фейспалм вызывает. Чувак 19 лет был домашним любимцем, как-то научился читать, а под конец вообще заговорил как человек без бэкграунда в виде жизни \"домашней собачкой\" и это за год скитаний...<br><br>Ах да, ещё открытый финал. Терпеть это не могу. Хотя может это начало цикла в задумке автора...<br><br>Ещё я так и не поняла смысл их \"сопротивления\". Сопротивление ради сопротивления? Где диверсии? Где попытки уничтожения хоть одного спонсора? Понятно, что они боялись ответной реакции, но вы же восстали против режима, значит понимали, что жертвы неизбежны. А по факту что мы видим: все противостояние заключается в мееедленом налаживании связей и не более того. Таким макаром спонсорам реальный отпор ещё через 100 лет начнут давать, даже с учётом того, что инспекция обо всём узнала. Я ещё всё посмеивалась над Тимом, когда он считал себя единственным кто \"прозрел\" и восстал против этих жаб. Но оказалось, он был единственный кто хоть как-то боролся. А кто же убил впервые спонсора? Да, наш супер-пупер-вундер мальчик. А не сопротивление, которое внедрило свои щупальца практически везде.<br><br>Я ожидала немного иного. Фантастику люблю, но «Любимец» мне не понравился.<br><br>",
         "2",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_slug</th>\n",
       "      <th>title_book</th>\n",
       "      <th>review_url</th>\n",
       "      <th>author_book</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>count_view</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>title_review</th>\n",
       "      <th>text_review</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5071651</td>\n",
       "      <td>Чубаркина Наталья Михайловна</td>\n",
       "      <td>1008751306-na-izyaschnom-mify-v-iskusstve-sovr...</td>\n",
       "      <td>#На изящном: мифы в искусстве. Современный взг...</td>\n",
       "      <td>https://www.livelib.ru/review/5071651-na-izyas...</td>\n",
       "      <td>Мария Аборонова</td>\n",
       "      <td>11 мая 2025 г. 10:23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>О мифах языком камеди- клаба.</td>\n",
       "      <td>1 из 5⭐О необходимости книги мы судим сначала ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5071642</td>\n",
       "      <td>nat_phil</td>\n",
       "      <td>1000460354-atlant-raspravil-plechi-v-3-chastya...</td>\n",
       "      <td>Атлант расправил плечи. В 3 частях. Часть 2. И...</td>\n",
       "      <td>https://www.livelib.ru/review/5071642-atlant-r...</td>\n",
       "      <td>Айн Рэнд</td>\n",
       "      <td>11 мая 2025 г. 10:19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Гнев да и только</td>\n",
       "      <td>Эта книжка меня жутко бесила: в смысле автор п...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5071639</td>\n",
       "      <td>Крупкина Мария</td>\n",
       "      <td>1008875347-na-zapadnom-fronte-bez-peremen-erih...</td>\n",
       "      <td>На Западном фронте без перемен</td>\n",
       "      <td>https://www.livelib.ru/review/5071639-na-zapad...</td>\n",
       "      <td>Эрих Мария Ремарк</td>\n",
       "      <td>11 мая 2025 г. 10:18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>СпойлерУжасы войны</td>\n",
       "      <td>Сразу после школы в 19 лет Пауля Боймера и его...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5071636</td>\n",
       "      <td>Жукова Елена</td>\n",
       "      <td>1010717885-sirena-morskih-glubin-sumi-han</td>\n",
       "      <td>Сирена морских глубин</td>\n",
       "      <td>https://www.livelib.ru/review/5071636-sirena-m...</td>\n",
       "      <td>Суми Хан</td>\n",
       "      <td>11 мая 2025 г. 10:17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Эх, разочарование...</td>\n",
       "      <td>«Жить — значит выживать и выполнять свой долг,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5071624</td>\n",
       "      <td>Booksevil</td>\n",
       "      <td>1005765304-lyubimets-kir-bulychjov</td>\n",
       "      <td>Любимец</td>\n",
       "      <td>https://www.livelib.ru/review/5071624-lyubimet...</td>\n",
       "      <td>Кир Булычёв</td>\n",
       "      <td>11 мая 2025 г. 10:11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>СпойлерСказ о том, как межпланетные лягухи нар...</td>\n",
       "      <td>Планета Земля. Она молода, красива и зелена. О...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   author_name  \\\n",
       "0  5071651  Чубаркина Наталья Михайловна   \n",
       "1  5071642                      nat_phil   \n",
       "2  5071639                Крупкина Мария   \n",
       "3  5071636                  Жукова Елена   \n",
       "4  5071624                     Booksevil   \n",
       "\n",
       "                                           book_slug  \\\n",
       "0  1008751306-na-izyaschnom-mify-v-iskusstve-sovr...   \n",
       "1  1000460354-atlant-raspravil-plechi-v-3-chastya...   \n",
       "2  1008875347-na-zapadnom-fronte-bez-peremen-erih...   \n",
       "3          1010717885-sirena-morskih-glubin-sumi-han   \n",
       "4                 1005765304-lyubimets-kir-bulychjov   \n",
       "\n",
       "                                          title_book  \\\n",
       "0  #На изящном: мифы в искусстве. Современный взг...   \n",
       "1  Атлант расправил плечи. В 3 частях. Часть 2. И...   \n",
       "2                     На Западном фронте без перемен   \n",
       "3                              Сирена морских глубин   \n",
       "4                                            Любимец   \n",
       "\n",
       "                                          review_url        author_book  \\\n",
       "0  https://www.livelib.ru/review/5071651-na-izyas...    Мария Аборонова   \n",
       "1  https://www.livelib.ru/review/5071642-atlant-r...           Айн Рэнд   \n",
       "2  https://www.livelib.ru/review/5071639-na-zapad...  Эрих Мария Ремарк   \n",
       "3  https://www.livelib.ru/review/5071636-sirena-m...           Суми Хан   \n",
       "4  https://www.livelib.ru/review/5071624-lyubimet...        Кир Булычёв   \n",
       "\n",
       "          date_creation count_view evaluation  \\\n",
       "0  11 мая 2025 г. 10:23          0          1   \n",
       "1  11 мая 2025 г. 10:19          0          5   \n",
       "2  11 мая 2025 г. 10:18          0          5   \n",
       "3  11 мая 2025 г. 10:17          0          3   \n",
       "4  11 мая 2025 г. 10:11          0          3   \n",
       "\n",
       "                                        title_review  \\\n",
       "0                      О мифах языком камеди- клаба.   \n",
       "1                                   Гнев да и только   \n",
       "2                                 СпойлерУжасы войны   \n",
       "3                               Эх, разочарование...   \n",
       "4  СпойлерСказ о том, как межпланетные лягухи нар...   \n",
       "\n",
       "                                         text_review count_like count_comment  \n",
       "0  1 из 5⭐О необходимости книги мы судим сначала ...          1             0  \n",
       "1  Эта книжка меня жутко бесила: в смысле автор п...          0             0  \n",
       "2  Сразу после школы в 19 лет Пауля Боймера и его...          1             0  \n",
       "3  «Жить — значит выживать и выполнять свой долг,...          1             0  \n",
       "4  Планета Земля. Она молода, красива и зелена. О...          2             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просмотр данных\n",
    "df_reviews = pd.DataFrame(data=reviews_list)\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_review",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "id_comment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_comment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_comment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "text_comment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "parent_comment",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5f95b0e7-0b02-4e17-8ef4-b502f2f31d36",
       "rows": [],
       "shape": {
        "columns": 6,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>date_comment</th>\n",
       "      <th>text_comment</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_review, id_comment, author_comment, date_comment, text_comment, parent_comment]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просмотр данных\n",
    "df_comments_reviews = pd.DataFrame(data=comments_reviews_list)\n",
    "df_comments_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55504517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение данных\n",
    "file_reviews = 'reviews.cvs'\n",
    "df_reviews.to_csv(file_reviews)\n",
    "\n",
    "file_comments_reviews = 'comments_reviews.cvs'\n",
    "df_comments_reviews.to_csv(file_comments_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd2672",
   "metadata": {},
   "source": [
    "### Парсинг подборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b17458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Структуры для хранения данных\n",
    "collections_list = {\n",
    "    'id': [],\n",
    "    'author_name': [],\n",
    "    'date_creation': [],\n",
    "    'count_view': [],\n",
    "    'count_book': [],\n",
    "    'title': [],\n",
    "    'collection_url': [],\n",
    "    'desc': [],\n",
    "    'count_like': [],\n",
    "    'count_comment': [],\n",
    "    'count_saved': [],\n",
    "    'books': {\n",
    "        'id_book': [],\n",
    "        'title_book': [],\n",
    "        'author_book': []\n",
    "    }\n",
    "}\n",
    "\n",
    "comments_collections_list = {\n",
    "    'id_collection': [],\n",
    "    'id_comment': [],\n",
    "    'author_comment': [],\n",
    "    'date_comment': [],\n",
    "    'text_comment': [],\n",
    "    'parent_comment': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae148b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки\n",
    "headers = {'User-Agent': UserAgent().random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f88cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг описания подборки\n",
    "def parse_collection_desc(desc_block):\n",
    "    if not desc_block:\n",
    "        return ''\n",
    "    \n",
    "    desc_div = desc_block.find('div', class_='description')\n",
    "    if not desc_div:\n",
    "        direct_text = desc_block.find('p')\n",
    "        if direct_text and direct_text.text.strip() != \"Нет описания\":\n",
    "            return direct_text.text.strip()\n",
    "        return ''\n",
    "    \n",
    "    processed_text = []\n",
    "\n",
    "    for element in desc_div.children:\n",
    "        if element.name == 'p':\n",
    "            # Обработка содержимое параграфа\n",
    "            para_content = []\n",
    "            for content in element.contents:\n",
    "                if content.name in ['b', 'i', 'u', 'a', 'span']:\n",
    "                    # Сохранение тегов форматирования\n",
    "                    tag = content.name\n",
    "                    text = content.get_text()\n",
    "                    if tag == 'a' or tag == 'span':\n",
    "                        para_content.append(text)\n",
    "                    else:\n",
    "                        para_content.append(f'<{tag}>{text}</{tag}>')\n",
    "                elif content.name is None:\n",
    "                    para_content.append(str(content))\n",
    "            \n",
    "            # Сбор текст параграфа и добавляем <br>\n",
    "            para_text = ''.join(para_content).strip()\n",
    "            if para_text:\n",
    "                processed_text.append(para_text)\n",
    "                processed_text.append('<br><br>')  # Двойной <br> для абзаца\n",
    "        \n",
    "        elif element.name == 'br':\n",
    "            processed_text.append('<br>')\n",
    "    \n",
    "    # Объединение все части\n",
    "    final_text = ''.join(processed_text)\n",
    "    \n",
    "    # Очистка лишние переносы\n",
    "    final_text = re.sub(r'(<br>\\s*){3,}', '<br><br>', final_text)\n",
    "    final_text = final_text.strip()\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e99af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг информации о книге в подборке\n",
    "def parse_book(book_div):\n",
    "    if not book_div:\n",
    "        return None\n",
    "    \n",
    "    # ID\n",
    "    book_id = None\n",
    "    cover_link = book_div.find('a', href=lambda x: x and ('/book/' in x or '/work/' in x))\n",
    "    if cover_link:\n",
    "        match = re.search(r'/(?:book|work)/(\\d+)', cover_link['href'])\n",
    "        book_id = match.group(1) if match else None\n",
    "\n",
    "    # Название\n",
    "    title = None\n",
    "    title_element = book_div.find('a', class_='brow-book-name')\n",
    "    if title_element:\n",
    "        title = title_element.get('title', '').split(' - ')[-1].strip() or title_element.text.strip()\n",
    "\n",
    "    # Авторы\n",
    "    authors = []\n",
    "    author_elements = book_div.find_all('a', class_='brow-book-author')\n",
    "    for elem in author_elements:\n",
    "        author_name = elem.get('title', '').strip() or elem.text.strip()\n",
    "        if author_name and author_name not in authors:\n",
    "            authors.append(author_name)\n",
    "\n",
    "    if not authors and title_element and ' - ' in title_element.get('title', ''):\n",
    "        possible_author = title_element['title'].split(' - ')[0].strip()\n",
    "        if possible_author:\n",
    "            authors.append(possible_author)\n",
    "\n",
    "    return {\n",
    "        'id_book': book_id,\n",
    "        'title_book': title,\n",
    "        'author_book': authors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг книг в подборке\n",
    "def parse_collection_books(collection_url, collection_id):\n",
    "    base_url = f'https://www.livelib.ru{collection_url}/listview/biglist'\n",
    "    page = 1\n",
    "    books = []\n",
    "\n",
    "    while True:\n",
    "        url = f'{base_url}/~{page}#books' if page > 1 else f'{base_url}#books'\n",
    "        print(f'[{datetime.now().strftime(\"%H:%M:%S\")}] Загрузка страницы {page}: {url} .')\n",
    "\n",
    "        try:\n",
    "            # Задержка перед загрузкой страницы с книгами\n",
    "            time.sleep(get_medium_delay())\n",
    "\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            if response.status_code != 200:\n",
    "                print(f'Ошибка загрузке страницы {page}: {url} .')\n",
    "                time.sleep(get_long_delay())\n",
    "                break\n",
    "\n",
    "            soup = bs(response.text, 'html.parser')\n",
    "            print(f'soup books, \\n{soup}')\n",
    "\n",
    "            # Проверка на блокировку\n",
    "            if 'идёт слишком много запросов' in response.text:\n",
    "                delay = get_extended_delay()\n",
    "                print(f'Блокировка. Большая пауза ({delay:.1f} сек).')\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "\n",
    "            # book_divs = soup.select('div[id^=\"my-selection-book-list-tr-\"]')\n",
    "            book_container = soup.find('div', class_='blist-biglist')\n",
    "            book_divs = book_container.find_all('div', id=lambda x: x and x.startswith('my-selection-book-list-tr-'))\n",
    "            print(f'Найдено {len(book_divs)} книг на странице {page}.')\n",
    "            \n",
    "            # Обработка книг с паузами\n",
    "            for i, book_div in enumerate(book_divs, 1):\n",
    "                if i % 5 == 0:\n",
    "                    time.sleep(get_short_delay())\n",
    "\n",
    "                book_info = parse_book(book_div)\n",
    "                if book_info['id_book']:\n",
    "                    books.append(book_info)\n",
    "\n",
    "            # Проверка пагинации\n",
    "            pagination = soup.find('div', id='booklist-pagination')\n",
    "            if not pagination:\n",
    "                break\n",
    "\n",
    "            next_page = pagination.find('a', id=lambda x: x and 'a-list-page-next' in x)\n",
    "            if not next_page or 'disabled' in next_page.get('class', []):\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Ошибка при парсинге страницы {page}: {str(e)} .')\n",
    "            time.sleep(get_long_delay())\n",
    "            break\n",
    "\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae600b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг комментариев к подборке\n",
    "def parse_collection_comments(collection_id, collection_url):\n",
    "    base_url = f'https://www.livelib.ru{collection_url}/comments'\n",
    "    page = 1\n",
    "    all_comments = []\n",
    "\n",
    "    while True:\n",
    "        url = f'{base_url}/~{page}#comments' if page > 1 else f'{base_url}#comments'\n",
    "        print(f'[{datetime.now().strftime(\"%H:%M:%S\")}] Парсинг комментариев страницы {page}: {url} .')\n",
    "\n",
    "        try:\n",
    "            # Задержка перед загрузкой комментариев\n",
    "            time.sleep(get_medium_delay())\n",
    "\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            soup = bs(response.text, 'html.parser')\n",
    "\n",
    "            # Проверка на блокировку\n",
    "            if 'идёт слишком много запросов' in response.text:\n",
    "                print('Блокировка. Большая пауза...')\n",
    "                time.sleep(get_extended_delay())\n",
    "\n",
    "            comments_block = soup.find('div', class_='commentnodes')\n",
    "            if not comments_block:\n",
    "                break\n",
    "\n",
    "            comments = comments_block.find_all('div', class_=lambda x: x and 'comment-row' in x)\n",
    "            print(f'Найдено {len(comments)} комментариев на странице.')\n",
    "\n",
    "            # Обработка комментариев\n",
    "            for i, comment in enumerate(comments, 1):\n",
    "                if i % 3 == 0:\n",
    "                    time.sleep(get_short_delay())\n",
    "\n",
    "                try:\n",
    "                    comment_id = comment.get('id', '').replace('comment', '')\n",
    "                    comment_level = int(comment['class'][1].split('comment-level')[1])\n",
    "\n",
    "                    author_tag = comment.find('a', class_='comment-user-avatar')\n",
    "                    author = author_tag.get('title', 'Аноним').split('(')[0].strip() if author_tag else 'Аноним'\n",
    "\n",
    "                    date_span = comment.find('span', class_='event-user-date')\n",
    "                    date = date_span.get_text(strip=True).replace('&nbsp;', ' ') if date_span else None\n",
    "\n",
    "                    text = ''\n",
    "                    text_div = comment.find('div', classs_='commenttext')\n",
    "                    if text_div:\n",
    "                        for elem in text_div.find_all(['img', 'a', 'script']):\n",
    "                            elem.decompose()\n",
    "                        text = ' '.join(text_div.stripped_strings)\n",
    "                    else:\n",
    "                        text = None\n",
    "\n",
    "                    parent = None\n",
    "                    if comment_level > 0:\n",
    "                        parent_block = comment.find_parent('div', id=lambda x: x and 'commentbranch' in x)\n",
    "                        if parent_block:\n",
    "                            parent = parent_block['id'].replace('commentbranch', '')\n",
    "\n",
    "                    all_comments.append({\n",
    "                        'id_collection': collection_id,\n",
    "                        'id_comment': comment_id,\n",
    "                        'author_comment': author,\n",
    "                        'date_comment': date,\n",
    "                        'text_comment': text,\n",
    "                        'parent_comment': parent\n",
    "                    })\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка парсинга комментария {comment.get('id')}: {str(e)} .')\n",
    "                    continue\n",
    "\n",
    "            # Проверка пагинации\n",
    "            next_page = soup.find('a', id=lambda x: x and 'a-list-page-next' in x)\n",
    "            if not next_page or 'disabled' in next_page.get('class', []):\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Ошибка при загрузке страницы {page}: {str(e)} .')\n",
    "            time.sleep(get_long_delay())\n",
    "            break\n",
    "\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a895ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция парсинга подборок\n",
    "def scrape_collections(start_page=1, max_pages=5):\n",
    "    pagenum = start_page\n",
    "    request_count = 0\n",
    "\n",
    "    for _ in range(max_pages):\n",
    "        try:\n",
    "            url = f'https://www.livelib.ru/selections/~{pagenum}'\n",
    "            print(f'\\n[{datetime.now().strftime(\"%H:%M:%S\")}] Страница {pagenum}: {url} .')\n",
    "\n",
    "            # Задержки\n",
    "            request_count += 1\n",
    "            if request_count % 3 == 0:\n",
    "                delay = get_long_delay()\n",
    "                print(f'Большая пауза на {delay:.1f} сек...')\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                time.sleep(get_medium_delay())\n",
    "\n",
    "            # Загрузка страницы с подборками\n",
    "            page = requests.get(url, headers=headers, timeout=30)\n",
    "            print(page.text)\n",
    "\n",
    "            # Проверка на блокировку\n",
    "            if 'идёт слишком много запросов' in page.text:\n",
    "                delay = get_extended_delay()\n",
    "                print(f'Блокировка. Большая пауза ({delay:.1f} сек).')\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "\n",
    "            if page.status_code != 200:\n",
    "                print(f'Ошибка загрузки страницы: {page.status_code}.')\n",
    "                time.sleep(get_extended_delay())\n",
    "                continue\n",
    "\n",
    "            soup = bs(page.text, 'html.parser')\n",
    "            print(soup)\n",
    "\n",
    "            # Поиск подборок\n",
    "            collection_cards = soup.find_all('article', class_=lambda x: x and 'bc-card' in x)\n",
    "            if not collection_cards:\n",
    "                print('Подборки не найдены, возможно блокировка или последняя страница.')\n",
    "                time.sleep(get_extended_delay())\n",
    "                break\n",
    "\n",
    "            print(f'Найдено {len(collection_cards)} подборок.')\n",
    "\n",
    "            # Обработка каждой подборки\n",
    "            for i, collection_card in enumerate(collection_cards, 1):\n",
    "                try:\n",
    "                    # Задержка между подборками\n",
    "                    if i % 2 == 0:\n",
    "                        time.sleep(get_short_delay())\n",
    "\n",
    "                    # ID\n",
    "                    collection_id = collection_card.get('data-object_id')\n",
    "                    if not collection_card:\n",
    "                        continue\n",
    "\n",
    "                    print(f'\\nОбработка подборки {i}/{len(collection_cards)} (ID: {collection_id}).')\n",
    "\n",
    "                    # Заголовок и URL\n",
    "                    title_link = collection_card.find('a', class_='bc-card__text-block-title-link')\n",
    "                    if not title_link:\n",
    "                        continue\n",
    "\n",
    "                    title = title_link.text.strip()\n",
    "                    href = title_link['href']\n",
    "                    full_url = urljoin('https://www.livelib.ru', href)\n",
    "\n",
    "                    # Автор и дата\n",
    "                    header_wrapper = collection_card.find('div', class_='bc-card__header-wrapper')\n",
    "                    author_name = 'Неизвестно'\n",
    "                    date_creation = 'Дата не указана'\n",
    "\n",
    "                    if header_wrapper:\n",
    "                        author_tag = header_wrapper.find('a', class_='bc-card__user-name-link')\n",
    "                        author_name = author_tag.text.strip() if author_tag else author_name\n",
    "\n",
    "                        date_tag = header_wrapper.find('time', class_=lambda x: x and 'bc-card__meta_type_time' in x)\n",
    "                        date_creation = date_tag.text.strip() if date_tag else date_creation\n",
    "\n",
    "                    # Количество просмотров\n",
    "                    count_view = 0\n",
    "                    count_view_item = collection_card.find('p', class_='bc-card__meta_type_views')\n",
    "                    if count_view_item:\n",
    "                        count_text = count_view_item.text.strip()\n",
    "                        count_view = int(re.sub(r'[^\\d]', '', count_text)) if count_text else 0\n",
    "\n",
    "                    # Количество книг\n",
    "                    count_book = 0\n",
    "                    content_block = collection_card.find('div', class_='bc-card__text-block')\n",
    "                    if content_block:\n",
    "                        count_book_item = content_block.find('span', class_=lambda x: x and 'bc-card__meta_type_book-count' in x)\n",
    "                        if count_book_item:\n",
    "                            count_text = count_book_item.text.strip()\n",
    "                            count_book = int(re.sub(r'[^\\d]', '', count_text)) if count_text else 0\n",
    "\n",
    "                    # Загрузка страницы подборки\n",
    "                    time.sleep(get_medium_delay())\n",
    "                    collection_page = requests.get(full_url, headers=headers, timeout=30)\n",
    "                    if collection_page.status_code != 200:\n",
    "                        print(f'Ошибка загрузки подборки: {collection_page.status_code}.')\n",
    "                        continue\n",
    "\n",
    "                    collection_soup = bs(collection_page.text, 'html.parser')\n",
    "\n",
    "                    # Описание подборки\n",
    "                    desc_block = collection_soup.find('div', class_='with-pad')\n",
    "                    desc = parse_collection_desc(desc_block) if desc_block else ''\n",
    "\n",
    "                    # Лайки, комментарии, сохранения\n",
    "                    likes = comments = saves = 0\n",
    "                    footer_container = collection_soup.find('div', class_='acb-selection-7761-main')\n",
    "\n",
    "                    if footer_container:\n",
    "                        # Лайки\n",
    "                        like_span = footer_container.find('span', id='vote-plus-span-selection-7761')\n",
    "                        if like_span:\n",
    "                            like_text = like_span.get_text(strip=True)\n",
    "                            likes = int(re.sub(r'[^\\d]', '', like_text)) if like_text else 0\n",
    "\n",
    "                        # Комментарии\n",
    "                        comment_span = footer_container.find('span', class_='count')\n",
    "                        if comment_span:\n",
    "                            comment_text = comment_span.get_text(strip=True)\n",
    "                            comments = int(re.sub(r'[^\\d]', '', comment_text)) if comment_text else 0\n",
    "\n",
    "                        # Сохранения\n",
    "                        save_span = footer_container.find('span', class_='count-in-fav')\n",
    "                        if save_span:\n",
    "                            save_text = save_span.get_text(strip=True)\n",
    "                            saves = int(re.sub(r'[^\\d]', '', save_text)) if save_text else 0\n",
    "\n",
    "                    # Парсинг книг в подборке\n",
    "                    books = []\n",
    "                    if count_book > 0:\n",
    "                        print(f'Парсинг {count_book} книг в подборке.')\n",
    "                        books = parse_collection_books(href, collection_id)\n",
    "                        print(f'Успешно собрано {len(books)} книг.')\n",
    "\n",
    "                    # Парсинг комментариев\n",
    "                    collection_comments = []\n",
    "                    if comments > 0:\n",
    "                        print(f'Паринг {comments} комментариев.')\n",
    "                        collection_comments = parse_collection_comments(collection_id, href)\n",
    "                        print(f'Успешно собрано {len(collection_comments)} комментариев.')\n",
    "\n",
    "                    # Сохранение данных\n",
    "                    collections_list['id'].append(collection_id)\n",
    "                    collections_list['author_name'].append(author_name)\n",
    "                    collections_list['date_creation'].append(date_creation)\n",
    "                    collections_list['count_view'].append(count_view)\n",
    "                    collections_list['count_book'].append(count_book)\n",
    "                    collections_list['title'].append(title)\n",
    "                    collections_list['collection_url'].append(full_url)\n",
    "                    collections_list['desc'].append(desc)\n",
    "                    collections_list['count_like'].append(likes)\n",
    "                    collections_list['count_comment'].append(comments)\n",
    "                    collections_list['count_saved'].append(saves)\n",
    "\n",
    "                    # Сохранение книг\n",
    "                    for book in books:\n",
    "                        collections_list['books']['id_book'].append(book['id_book'])\n",
    "                        collections_list['books']['title_book'].append(book['title_book'])\n",
    "                        collections_list['books']['author_book'].append(book['author_book'])\n",
    "\n",
    "                    # Сохранение комментариев\n",
    "                    for comment in collection_comments:\n",
    "                        for key in comments_collections_list:\n",
    "                            if key in comment:\n",
    "                                comments_collections_list[key].append(comment[key])\n",
    "\n",
    "                    print(f'Подборка {title} успешо обработана.')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка обработки подборки: {str(e)} .')\n",
    "                    time.sleep(get_long_delay())\n",
    "                    continue\n",
    "\n",
    "            pagenum += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Критическая ошибка: {str(e)} .')\n",
    "            time.sleep(get_extended_delay())\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало парсинга: 21:32:40\n",
      "\n",
      "[21:32:40] Страница 1: https://www.livelib.ru/selections/~1 .\n",
      "<html>\n",
      "<head>\n",
      "<title>LiveLib</title>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://s.livelib.ru/css/style.1.css\" />\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://s.livelib.ru/skins/ll2015b/css/style.1.css\" />\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://s.livelib.ru/skins/ll2015b/css/stylev4.1.css\" />\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "\n",
      "<div style=\"display: none;\">\n",
      "    <!--LiveInternet counter--><script type=\"text/javascript\"><!--\n",
      "        document.write(\"<img src='https://counter.yadro.ru/hit?r\" +\n",
      "                escape(document.referrer) + ((typeof (screen) == \"undefined\") ? \"\" :\n",
      "                \";s\" + screen.width + \"*\" + screen.height + \"*\" + (screen.colorDepth ?\n",
      "                        screen.colorDepth : screen.pixelDepth)) + \";u\" + escape(document.URL) +\n",
      "                \";\" + Math.random() +\n",
      "                \"' width=1 height=1 alt=''>\")//--></script><!--/LiveInternet-->\n",
      "\n",
      "        </div>    \n",
      "    \n",
      "<div style=\"position: relative; overflow: hidden; width: 100%; height: 50px; background: #0768d8;\">\n",
      "    <div style=\"position: absolute; right: 28px;\" id=\"logo\"><a href=\"http://www.livelib.ru\"><img src=\"https://s.livelib.ru/img/logo_white.png\" alt=\"LiveLib &#151; социальная сеть читателей книг\"></a>\n",
      "    </div>\n",
      "</div>\n",
      "<div id=\"bodywrapper\">\n",
      "    <div id=\"innerwrapper\">\n",
      "    <div id=\"contentwrapper\">\n",
      "        <div style=\"margin:0 auto;\">\n",
      "        <div class=\"container\">                                              \n",
      "            <div class=\"page-404\">\n",
      "                <div id=\"captcha-show\" class=\"p\">\n",
      "                    <h1>Пожалуйста, подождите пару секунд, идет перенаправление на сайт...</h1>\n",
      "                </div>\n",
      "                <div id=\"captcha-hide\" style=\"display:none;\">\n",
      "                    <form action=\"/service/ratelimitcaptcha\" method=\"POST\" class=\"p\" style=\"text-align:center;\">\n",
      "                        <h1>С вашего адреса или из вашей сети идёт слишком много запросов к Лайвлибу.<br>Пожалуйста, введите текст с картинки, чтобы продолжить работу с сайтом.</h1>\n",
      "                        <p><img src=\"/service/captcha\" alt=\"Капча\" width=\"100\" height=\"60\"><br><br>\n",
      "                        <input type=\"text\" id=\"form[captcha]\" name=\"form[captcha]\" style=\"font-size:20px;padding:5px;\"><br><br>\n",
      "                        <input type=\"submit\" class=\"btn200\" style=\"font-size:18px;padding-top:15px;padding-bottom:25px;font-weight:bold;\" value=\"Вернуться\" name=\"btn_go\">\n",
      "                        </p>\n",
      "                    </form>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    </div>\n",
      "</div>\n",
      "<script type=\"text/javascript\" src=\"https://s.livelib.ru/js/ratelimit.202504290619.js\"></script>\n",
      "<div id=\"grecaptcha-badge-footer\"></div>\n",
      "<div class=\"grecaptcha-badge-container\">\n",
      "    \n",
      "        <script src=\"https://www.google.com/recaptcha/api.js?render=6Lei-n4UAAAAAK-kITVN7q0IATLTn7ClfLzO3NFL\"></script>\n",
      "        <script>\n",
      "            grecaptcha.ready(function() {\n",
      "                grecaptcha.execute('6Lei-n4UAAAAAK-kITVN7q0IATLTn7ClfLzO3NFL', {action: 'ratelimit'}).then(function(token) {\n",
      "                   grecaptcha_verify(token, 'ratelimit', 'https://www.livelib.ru//selections');\n",
      "                });\n",
      "            });\n",
      "        </script>\n",
      "    \n",
      "</div>\n",
      "<script async src=\"https://www.googletagmanager.com/gtag/js?id=G-90RPM8SDHL\"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-90RPM8SDHL', {'site_version': 'mobile', 'user_type': 'guest'});</script>\n",
      "<script type=\"text/javascript\" >(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})(window,document,\"script\",\"https://mc.yandex.ru/metrika/tag.js\",\"ym\");ym(127861,\"init\",{clickmap:false,trackLinks:true,accurateTrackBounce:true,webvisor:false});</script><noscript><div><img src=\"https://mc.yandex.ru/watch/127861\" style=\"position:absolute; left:-9999px;\" alt=\"\" /></div></noscript>\n",
      "    <script type=\"text/javascript\">\n",
      "        (function(e, x, pe, r, i, me, nt){\n",
      "        e[i]=e[i]||function(){(e[i].a=e[i].a||[]).push(arguments)},\n",
      "        me=x.createElement(pe),me.async=1,me.src=r,nt=x.getElementsByTagName(pe)[0],me.addEventListener(\"error\",function(){function cb(t){t=t[t.length-1],\"function\"==typeof t&&t({flags:{}})};Array.isArray(e[i].a)&&e[i].a.forEach(cb);e[i]=function(){cb(arguments)}}),nt.parentNode.insertBefore(me,nt)})\n",
      "        (window, document, 'script', 'https://abt.s3.yandex.net/expjs/latest/exp.js', 'ymab');\n",
      "\n",
      "        ymab('metrika.127861', 'setConfig', {\n",
      "            enableVisual: true,\n",
      "            enableJS: true,\n",
      "            enableHTML: true,\n",
      "            enableWatch: true,\n",
      "            storeReferer: true\n",
      "        });\n",
      "\n",
      "        ymab('metrika.127861', 'init');\n",
      "    </script>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "Блокировка. Большая пауза (273.7 сек).\n"
     ]
    }
   ],
   "source": [
    "print(f'Начало парсинга: {datetime.now().strftime('%H:%M:%S')}')\n",
    "scrape_collections(start_page=1, max_pages=5)\n",
    "print(f'Завершение парсинга: {datetime.now().strftime('%H:%M:%S')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad28013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр количества пропусков\n",
    "print('Количество нулевых значений в collections_list:')\n",
    "for i in collections_list:\n",
    "    print( i + \" - \" + str(collections_list[i].count(None)))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Количество нулевых значений в comments_collections_list:')\n",
    "for i in comments_collections_list:\n",
    "    print( i + \" - \" + str(comments_collections_list[i].count(None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577831da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр данных\n",
    "df_collections = pd.DataFrame(data=collections_list)\n",
    "df_collections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdd918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр данных\n",
    "df_comments_collections = pd.DataFrame(data=comments_collections_list)\n",
    "df_comments_collections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b50435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение данных\n",
    "file_collections = 'collections.cvs'\n",
    "df_collections.to_csv(file_collections)\n",
    "\n",
    "file_comments_collections = 'comments_collections.cvs'\n",
    "df_comments_collections.to_csv(file_comments_collections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
